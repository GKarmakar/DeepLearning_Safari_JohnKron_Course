{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we leverage an [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)-like deep, convolutional neural network to classify flowers into the 17 categories of the [Oxford Flowers](http://www.robots.ox.ac.uk/~vgg/data/flowers/17/) data set. Derived from [this earlier notebook](https://github.com/the-deep-learners/TensorFlow-LiveLessons/blob/master/notebooks/old/L3-3b__TFLearn_AlexNet.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard # for part 3.5 on TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load *and preprocess* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "X, Y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 1, 384)         1536      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1576960   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 21,883,153\n",
      "Trainable params: 21,881,681\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure TensorBoard (for part 5 of lesson 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorbrd = TensorBoard('logs/alexnet') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1224 samples, validate on 136 samples\n",
      "Epoch 1/100\n",
      "1224/1224 [==============================] - 35s - loss: 5.4212 - acc: 0.2067 - val_loss: 11.3663 - val_acc: 0.0956\n",
      "Epoch 2/100\n",
      "1224/1224 [==============================] - 35s - loss: 3.9938 - acc: 0.2492 - val_loss: 6.4582 - val_acc: 0.0735\n",
      "Epoch 3/100\n",
      "1224/1224 [==============================] - 34s - loss: 2.7325 - acc: 0.2949 - val_loss: 5.6394 - val_acc: 0.1324\n",
      "Epoch 4/100\n",
      "1224/1224 [==============================] - 34s - loss: 2.5455 - acc: 0.3031 - val_loss: 4.1848 - val_acc: 0.2206\n",
      "Epoch 5/100\n",
      "1224/1224 [==============================] - 34s - loss: 2.5307 - acc: 0.3317 - val_loss: 2.9730 - val_acc: 0.2426\n",
      "Epoch 6/100\n",
      "1224/1224 [==============================] - 35s - loss: 2.3763 - acc: 0.3448 - val_loss: 2.9469 - val_acc: 0.2426\n",
      "Epoch 7/100\n",
      "1224/1224 [==============================] - 35s - loss: 2.4945 - acc: 0.3448 - val_loss: 3.7506 - val_acc: 0.2574\n",
      "Epoch 8/100\n",
      "1224/1224 [==============================] - 36s - loss: 2.6480 - acc: 0.3660 - val_loss: 5.1129 - val_acc: 0.1691\n",
      "Epoch 9/100\n",
      "1224/1224 [==============================] - 34s - loss: 2.8148 - acc: 0.3268 - val_loss: 2.8049 - val_acc: 0.3603\n",
      "Epoch 10/100\n",
      "1224/1224 [==============================] - 34s - loss: 2.3363 - acc: 0.3905 - val_loss: 2.8927 - val_acc: 0.3603\n",
      "Epoch 11/100\n",
      "1224/1224 [==============================] - 34s - loss: 2.2786 - acc: 0.4060 - val_loss: 2.5592 - val_acc: 0.3162\n",
      "Epoch 12/100\n",
      "1224/1224 [==============================] - 34s - loss: 2.0467 - acc: 0.4281 - val_loss: 2.8987 - val_acc: 0.3382\n",
      "Epoch 13/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.9947 - acc: 0.4592 - val_loss: 2.1224 - val_acc: 0.3676\n",
      "Epoch 14/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.7445 - acc: 0.4910 - val_loss: 2.0347 - val_acc: 0.4412\n",
      "Epoch 15/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.8929 - acc: 0.4935 - val_loss: 2.3847 - val_acc: 0.4338\n",
      "Epoch 16/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.9688 - acc: 0.4583 - val_loss: 3.3796 - val_acc: 0.3529\n",
      "Epoch 17/100\n",
      "1224/1224 [==============================] - 35s - loss: 2.2440 - acc: 0.4436 - val_loss: 2.7138 - val_acc: 0.3750\n",
      "Epoch 18/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.9742 - acc: 0.5000 - val_loss: 2.8813 - val_acc: 0.4044\n",
      "Epoch 19/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.8282 - acc: 0.5049 - val_loss: 3.6857 - val_acc: 0.3750\n",
      "Epoch 20/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.8215 - acc: 0.5049 - val_loss: 2.2820 - val_acc: 0.5294\n",
      "Epoch 21/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.8518 - acc: 0.5212 - val_loss: 1.9001 - val_acc: 0.5074\n",
      "Epoch 22/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.7738 - acc: 0.5147 - val_loss: 2.0581 - val_acc: 0.5074\n",
      "Epoch 23/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.4318 - acc: 0.5784 - val_loss: 3.7218 - val_acc: 0.3456\n",
      "Epoch 24/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.6964 - acc: 0.5482 - val_loss: 3.9307 - val_acc: 0.2574\n",
      "Epoch 25/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.5907 - acc: 0.5621 - val_loss: 2.9847 - val_acc: 0.3897\n",
      "Epoch 26/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.6202 - acc: 0.5752 - val_loss: 3.7071 - val_acc: 0.3676\n",
      "Epoch 27/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.7010 - acc: 0.5547 - val_loss: 2.5451 - val_acc: 0.3897\n",
      "Epoch 28/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.5992 - acc: 0.5605 - val_loss: 3.3575 - val_acc: 0.3824\n",
      "Epoch 29/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.4056 - acc: 0.5989 - val_loss: 2.6031 - val_acc: 0.4559\n",
      "Epoch 30/100\n",
      "1224/1224 [==============================] - 26s - loss: 1.4243 - acc: 0.6217 - val_loss: 2.7693 - val_acc: 0.4485\n",
      "Epoch 31/100\n",
      "1224/1224 [==============================] - 24s - loss: 1.2810 - acc: 0.6176 - val_loss: 4.5931 - val_acc: 0.3603\n",
      "Epoch 32/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.3800 - acc: 0.6381 - val_loss: 2.9544 - val_acc: 0.4265\n",
      "Epoch 33/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.4526 - acc: 0.6087 - val_loss: 3.2366 - val_acc: 0.4559\n",
      "Epoch 34/100\n",
      "1224/1224 [==============================] - 26s - loss: 1.4056 - acc: 0.6332 - val_loss: 2.6401 - val_acc: 0.5294\n",
      "Epoch 35/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.5018 - acc: 0.5948 - val_loss: 4.3320 - val_acc: 0.3603\n",
      "Epoch 36/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.3303 - acc: 0.6381 - val_loss: 3.3895 - val_acc: 0.3971\n",
      "Epoch 37/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.2792 - acc: 0.6422 - val_loss: 2.9808 - val_acc: 0.4485\n",
      "Epoch 38/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.2895 - acc: 0.6356 - val_loss: 2.7670 - val_acc: 0.4632\n",
      "Epoch 39/100\n",
      "1224/1224 [==============================] - 30s - loss: 1.2147 - acc: 0.6520 - val_loss: 2.7203 - val_acc: 0.5147\n",
      "Epoch 40/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.2939 - acc: 0.6340 - val_loss: 3.2740 - val_acc: 0.4485\n",
      "Epoch 41/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.1160 - acc: 0.6797 - val_loss: 2.1987 - val_acc: 0.5074\n",
      "Epoch 42/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.9781 - acc: 0.7190 - val_loss: 2.5899 - val_acc: 0.5074\n",
      "Epoch 43/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.9695 - acc: 0.7288 - val_loss: 2.1273 - val_acc: 0.5147\n",
      "Epoch 44/100\n",
      "1224/1224 [==============================] - 31s - loss: 1.0449 - acc: 0.6912 - val_loss: 2.3803 - val_acc: 0.6176\n",
      "Epoch 45/100\n",
      "1224/1224 [==============================] - 35s - loss: 0.9135 - acc: 0.7516 - val_loss: 3.4901 - val_acc: 0.4706\n",
      "Epoch 46/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.7137 - acc: 0.7672 - val_loss: 2.5690 - val_acc: 0.5368\n",
      "Epoch 47/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.7864 - acc: 0.7606 - val_loss: 6.0906 - val_acc: 0.1471\n",
      "Epoch 48/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.8475 - acc: 0.7435 - val_loss: 4.1929 - val_acc: 0.4632\n",
      "Epoch 49/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.7135 - acc: 0.7876 - val_loss: 2.4818 - val_acc: 0.5809\n",
      "Epoch 50/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.6861 - acc: 0.7859 - val_loss: 2.4039 - val_acc: 0.6103\n",
      "Epoch 51/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.7028 - acc: 0.7966 - val_loss: 2.8229 - val_acc: 0.5441\n",
      "Epoch 52/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.8514 - acc: 0.7647 - val_loss: 2.4944 - val_acc: 0.5147\n",
      "Epoch 53/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.1566 - acc: 0.6846 - val_loss: 4.6325 - val_acc: 0.3529\n",
      "Epoch 54/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.7106 - acc: 0.5850 - val_loss: 4.7924 - val_acc: 0.3603\n",
      "Epoch 55/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.2370 - acc: 0.6789 - val_loss: 4.2017 - val_acc: 0.4338\n",
      "Epoch 56/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.1042 - acc: 0.6716 - val_loss: 2.4918 - val_acc: 0.5074\n",
      "Epoch 57/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.9409 - acc: 0.7198 - val_loss: 2.6726 - val_acc: 0.5956\n",
      "Epoch 58/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.9597 - acc: 0.7149 - val_loss: 2.1746 - val_acc: 0.5368\n",
      "Epoch 59/100\n",
      "1224/1224 [==============================] - 31s - loss: 1.0154 - acc: 0.7116 - val_loss: 2.1224 - val_acc: 0.6176\n",
      "Epoch 60/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.4147 - acc: 0.6667 - val_loss: 6.5234 - val_acc: 0.3015\n",
      "Epoch 61/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.8682 - acc: 0.5670 - val_loss: 6.0193 - val_acc: 0.2132\n",
      "Epoch 62/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.4930 - acc: 0.6078 - val_loss: 3.5747 - val_acc: 0.3971\n",
      "Epoch 63/100\n",
      "1224/1224 [==============================] - 26s - loss: 1.2548 - acc: 0.6650 - val_loss: 2.8592 - val_acc: 0.4412\n",
      "Epoch 64/100\n",
      "1224/1224 [==============================] - 32s - loss: 1.0849 - acc: 0.6895 - val_loss: 2.6487 - val_acc: 0.5368\n",
      "Epoch 65/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.9805 - acc: 0.7132 - val_loss: 3.6187 - val_acc: 0.4485\n",
      "Epoch 66/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.8874 - acc: 0.7418 - val_loss: 2.8937 - val_acc: 0.4926\n",
      "Epoch 67/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.7834 - acc: 0.7598 - val_loss: 2.8119 - val_acc: 0.5221\n",
      "Epoch 68/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.6975 - acc: 0.7819 - val_loss: 2.4226 - val_acc: 0.5074\n",
      "Epoch 69/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.6471 - acc: 0.8039 - val_loss: 2.2897 - val_acc: 0.5735\n",
      "Epoch 70/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.7631 - acc: 0.7819 - val_loss: 2.4562 - val_acc: 0.5882\n",
      "Epoch 71/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.6553 - acc: 0.7908 - val_loss: 2.3580 - val_acc: 0.5809\n",
      "Epoch 72/100\n",
      "1224/1224 [==============================] - 35s - loss: 0.5675 - acc: 0.8235 - val_loss: 2.9143 - val_acc: 0.5294\n",
      "Epoch 73/100\n",
      "1224/1224 [==============================] - 27s - loss: 0.5287 - acc: 0.8431 - val_loss: 2.9401 - val_acc: 0.5441\n",
      "Epoch 74/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.6145 - acc: 0.8203 - val_loss: 1.9691 - val_acc: 0.5882\n",
      "Epoch 75/100\n",
      "1224/1224 [==============================] - 24s - loss: 0.3952 - acc: 0.8685 - val_loss: 2.6215 - val_acc: 0.5882\n",
      "Epoch 76/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.4491 - acc: 0.8578 - val_loss: 2.3133 - val_acc: 0.5735\n",
      "Epoch 77/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.4666 - acc: 0.8554 - val_loss: 2.4880 - val_acc: 0.6324\n",
      "Epoch 78/100\n",
      "1224/1224 [==============================] - 30s - loss: 0.7113 - acc: 0.8145 - val_loss: 2.7856 - val_acc: 0.5809\n",
      "Epoch 79/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.6339 - acc: 0.8096 - val_loss: 3.5978 - val_acc: 0.5147\n",
      "Epoch 80/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.7559 - acc: 0.7827 - val_loss: 2.9329 - val_acc: 0.5368\n",
      "Epoch 81/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.3393 - acc: 0.6814 - val_loss: 11.2519 - val_acc: 0.0956\n",
      "Epoch 82/100\n",
      "1224/1224 [==============================] - 24s - loss: 2.3512 - acc: 0.4894 - val_loss: 4.9423 - val_acc: 0.2647\n",
      "Epoch 83/100\n",
      "1224/1224 [==============================] - 32s - loss: 1.9400 - acc: 0.5425 - val_loss: 4.1003 - val_acc: 0.3235\n",
      "Epoch 84/100\n",
      "1224/1224 [==============================] - 35s - loss: 1.6382 - acc: 0.5940 - val_loss: 2.6543 - val_acc: 0.4926\n",
      "Epoch 85/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.4111 - acc: 0.6324 - val_loss: 2.0040 - val_acc: 0.5735\n",
      "Epoch 86/100\n",
      "1224/1224 [==============================] - 34s - loss: 1.2437 - acc: 0.6912 - val_loss: 2.0457 - val_acc: 0.5294\n",
      "Epoch 87/100\n",
      "1224/1224 [==============================] - 25s - loss: 1.0179 - acc: 0.7067 - val_loss: 2.3981 - val_acc: 0.5956\n",
      "Epoch 88/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.9751 - acc: 0.7353 - val_loss: 2.8484 - val_acc: 0.4632\n",
      "Epoch 89/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.7592 - acc: 0.7745 - val_loss: 2.7576 - val_acc: 0.5221\n",
      "Epoch 90/100\n",
      "1224/1224 [==============================] - 24s - loss: 0.8512 - acc: 0.7623 - val_loss: 2.3349 - val_acc: 0.5882\n",
      "Epoch 91/100\n",
      "1224/1224 [==============================] - 27s - loss: 0.8372 - acc: 0.7500 - val_loss: 2.2602 - val_acc: 0.6471\n",
      "Epoch 92/100\n",
      "1224/1224 [==============================] - 33s - loss: 0.9406 - acc: 0.7361 - val_loss: 2.3562 - val_acc: 0.6250\n",
      "Epoch 93/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.9881 - acc: 0.7500 - val_loss: 2.2908 - val_acc: 0.5221\n",
      "Epoch 94/100\n",
      "1224/1224 [==============================] - 26s - loss: 0.8543 - acc: 0.7590 - val_loss: 2.5853 - val_acc: 0.5441\n",
      "Epoch 95/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.7622 - acc: 0.7949 - val_loss: 2.2524 - val_acc: 0.5956\n",
      "Epoch 96/100\n",
      "1224/1224 [==============================] - 25s - loss: 0.6826 - acc: 0.8105 - val_loss: 2.8272 - val_acc: 0.5368\n",
      "Epoch 97/100\n",
      "1224/1224 [==============================] - 29s - loss: 0.6542 - acc: 0.8219 - val_loss: 2.6472 - val_acc: 0.5662\n",
      "Epoch 98/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.6940 - acc: 0.7974 - val_loss: 2.4740 - val_acc: 0.5662\n",
      "Epoch 99/100\n",
      "1224/1224 [==============================] - 34s - loss: 0.5167 - acc: 0.8374 - val_loss: 2.2321 - val_acc: 0.6103\n",
      "Epoch 100/100\n",
      "1224/1224 [==============================] - 35s - loss: 0.4271 - acc: 0.8619 - val_loss: 2.3397 - val_acc: 0.6324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65dc6a7630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, validation_split=0.1, shuffle=True, \n",
    "          callbacks=[tensorbrd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
