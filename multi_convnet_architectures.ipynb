{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-ConvNet Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we concatenate *multiple parallel convolutional nets together* to classify IMDB movie reviews by their sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model # new!\n",
    "from keras.layers import Input, concatenate # new! \n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, Conv1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/multiconv'\n",
    "\n",
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64\n",
    "n_unique_words = 5000 \n",
    "max_review_length = 400\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# convolutional layer architecture:\n",
    "n_conv_1 = n_conv_2 = n_conv_3 = 256 \n",
    "k_conv_1 = 3\n",
    "k_conv_2 = 2\n",
    "k_conv_3 = 4\n",
    "\n",
    "# dense layer architecture: \n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start with conv_1 only and no concat\n",
    "# add conv_2\n",
    "# add conv_3\n",
    "# add dense_2\n",
    "\n",
    "input_layer = Input(shape=(max_review_length,), dtype='int16', name='input') # supports integers +/- 32.7k \n",
    "embedding_layer = Embedding(n_unique_words, n_dim, input_length=max_review_length, name='embedding')(input_layer)\n",
    "drop_embed_layer = SpatialDropout1D(drop_embed, name='drop_embed')(embedding_layer)\n",
    "\n",
    "conv_1 = Conv1D(n_conv_1, k_conv_1, activation='relu', name='conv_1')(drop_embed_layer)\n",
    "maxp_1 = GlobalMaxPooling1D(name='maxp_1')(conv_1)\n",
    "\n",
    "conv_2 = Conv1D(n_conv_1, k_conv_1, activation='relu', name='conv_2')(drop_embed_layer)\n",
    "maxp_2 = GlobalMaxPooling1D(name='maxp_2')(conv_2)\n",
    "\n",
    "conv_3 = Conv1D(n_conv_1, k_conv_1, activation='relu', name='conv_3')(drop_embed_layer)\n",
    "maxp_3 = GlobalMaxPooling1D(name='maxp_3')(conv_3)\n",
    "\n",
    "concat = concatenate([maxp_1, maxp_2, maxp_3])\n",
    "\n",
    "dense_layer = Dense(n_dense, activation='relu', name='dense')(concat)\n",
    "drop_dense_layer = Dropout(dropout, name='drop_dense')(dense_layer)\n",
    "dense_2 = Dense(64, activation='relu', name='dense_2')(drop_dense_layer)\n",
    "dropout_2 = Dropout(dropout, name='drop_dense_2')(dense_2)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid', name='output')(dropout_2)\n",
    "\n",
    "model = Model(input_layer, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input (InputLayer)               (None, 400)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 400, 64)       320000      input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "drop_embed (SpatialDropout1D)    (None, 400, 64)       0           embedding[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_1 (Conv1D)                  (None, 398, 256)      49408       drop_embed[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv_2 (Conv1D)                  (None, 398, 256)      49408       drop_embed[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv_3 (Conv1D)                  (None, 398, 256)      49408       drop_embed[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxp_1 (GlobalMaxPooling1D)      (None, 256)           0           conv_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "maxp_2 (GlobalMaxPooling1D)      (None, 256)           0           conv_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "maxp_3 (GlobalMaxPooling1D)      (None, 256)           0           conv_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 768)           0           maxp_1[0][0]                     \n",
      "                                                                   maxp_2[0][0]                     \n",
      "                                                                   maxp_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense (Dense)                    (None, 256)           196864      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "drop_dense (Dropout)             (None, 256)           0           dense[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            16448       drop_dense[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "drop_dense_2 (Dropout)           (None, 64)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 1)             65          drop_dense_2[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 681,601\n",
      "Trainable params: 681,601\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 35s - loss: 0.5101 - acc: 0.7158 - val_loss: 0.2918 - val_acc: 0.8781\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.2559 - acc: 0.8989 - val_loss: 0.2576 - val_acc: 0.8946\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.1732 - acc: 0.9366 - val_loss: 0.3052 - val_acc: 0.8766\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.1249 - acc: 0.9554 - val_loss: 0.2883 - val_acc: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf82460c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with conv_1 only and no concat: 89.1% validation accuracy in epoch 2, as earlier notebook\n",
    "# add conv_2: 89.5% in epoch 3\n",
    "# add conv_3: ditto\n",
    "# add dense_2: ditto in epoch 2\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.01.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf79ad8438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'96.08'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
